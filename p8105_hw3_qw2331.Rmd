---
title: "p8105_hw3_qw2331"
output: github_document
---

```{r, echo = FALSE, message = FALSE}
library(tidyverse)
library(p8105.datasets)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%",
  message = FALSE
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.coutinuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

**Load the `instacart` data**
```{r}
data("instacart")
inst_df <- instacart
```

**A brief description about `instacart`**
```{r}
# Quickly overview
summary(inst_df)
str(inst_df)
```
+ This dataset contains ``r nrow(inst_df)`` observations and ``r ncol(inst_df)`` variables.  
+ Among all the variables, there are `11` integer variables and `4` character variables.  
+ Of all the variables, which are ``r names(inst_df)``, respectively, the key variables are:  
  + `order_id` represents an order identifier;  
  + `product_id` represents a product identifier;    
  + `user_id` represents a customer identifier;  
  + `aisle_id` represents an aisle identifier;   
  + `department_id` represents a department identifier.    
+ Illustrative examples of observations are showing below:     
```{r, fig.width = 9}
# An illustrative example
items_day_p <- 
  inst_df %>% 
  filter(aisle %in% c("yogurt", "cream", "fresh fruits")) %>% 
  group_by(aisle, order_dow) %>% 
  summarize(n_purchase = n()) %>% 
  ggplot(aes(x = order_dow, y = n_purchase, color = aisle)) + 
  geom_point(alpha = .5) + 
  geom_smooth(se = FALSE, size = .5) + 
  labs(
    x = "Day of the week",
    y = "Purchased quantity",
    title = "An illustrative example",
    caption = "Data from p8105 package"
  )

items_day_p

# A brief description of the first row data
inst_df %>% 
  head(1) %>% 
  knitr::kable()
```

+ The plot shows that:  
  + `Fresh furits` had the highest sales volume compared with the other two;  
  + In generally, people will shop online using Instacart more frequently on Sunday.
+ The table shows that:
  + At 10 in the morning on Thursday, a customer with `user_id` 112108 bought a `Bulgarian Yogurt`, which `product_id` is 49302;
  + This product belongs to the `dairy eggs` department with `department_id` 16 and `yogurt` aisle with `aisle_id` 120;
  + This customer had bought this product before and for this time he/she added this same product into the shopping cart in the first place order (`add_to_cart_order` = 1);
  + It was the fourth time (`order_number` = 4) this customer shopping online using Instacart and it had been nine days since his/her last shopping trip (`days_since_prior_order` = 9).

**Answer the following questions**  
+ How many aisles are there, and which aisles are the most items ordered from?
```{r}
n_items_of_aisle <- 
  inst_df %>% 
  count(aisle, name = "n_items") %>% 
  arrange(desc(n_items))

n_items_of_aisle
```
There are ``r length(unique(pull(inst_df, aisle)))`` aisles in this dataset;
Most items are ordered from the aisle `fresh vegetables`.

+ Make a plot that shows the number of items ordered in each aisle, limiting this to aisle with more than 10000 items ordered. Arrange aisles sensibly, and organize your plot so others can read it.
```{r, warning = FALSE, fig.width = 9}
n_items_of_aisle %>% 
  filter(n_items > 10000) %>% 
  mutate(
    aisle = fct_reorder(aisle, n_items)
  ) %>% 
  ggplot(aes(x = n_items, y = aisle, fill = aisle)) +
  geom_bar(
    stat = "identity",
    show_guide = FALSE
    ) + 
  geom_text(aes(label = n_items), size = 2.5, hjust = 0) + 
  labs(
    x = "Number of items ordered",
    y = "Aisle",
    title = "Number of items ordered in each aisle",
    caption = "Data from p8105 package"
  )
```

+ Make a table showing the three most popular items in each of the aisles "baking ingredients", "dog food care", and "packaged vegetables fruits". Include the number of times each item is ordered in your table.
```{r}
inst_df %>% 
  filter(
    aisle %in% 
      c("baking ingredients", "dog food care", "packaged vegetables fruits")
  ) %>% 
  group_by(aisle, product_name) %>%
  summarize(number_items = n()) %>% 
  arrange(desc(number_items)) %>% 
  do(head(., n = 3)) %>% 
  knitr::kable(
    caption = "Top 3 most popular items",
    align = "c"
  )
```

+ Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week; format this table for human readers (i.e. produce a 2 * 7 table)
```{r}
inst_df %>% 
  filter(
    product_name %in%
      c("Pink Lady Apples", "Coffee Ice Cream")
  ) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(
    mean_hour = mean(order_hour_of_day)
  ) %>% 
  mutate(
    order_dow = weekdays(as.Date("2021-10-17") + 0:6)[order_dow + 1]
  ) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  ) %>% 
  knitr::kable(
    digits = 1,
    caption = "Mean hour of a day ordered",
    align = "c")
```


## Problem 2

**Load the `BRFSS` data**
```{r}
data("brfss_smart2010")
brfss_df <- brfss_smart2010
```

**Do some data cleaning**
```{r}
brfss_df <- 
  brfss_df %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health") %>% 
  mutate(
    response = factor(response,
                      levels = c("Poor", "Fair", "Good", "Very good", "Excellent"),
                      ordered = TRUE)
  )
```

**Answer the following questions**  
+ In 2002, which states were observed at 7 or more locations? What about 2010?
```{r}
# Number of locations in 2002
loc_2002 <- 
  brfss_df %>% 
  filter(year == 2002) %>% 
  group_by(locationabbr) %>% 
  summarize(n_locations = n()/5) %>% 
  filter(n_locations >= 7) %>% 
  arrange(n_locations)

loc_2002 %>%   
  knitr::kable(
    caption = "Number of locations in 2002",
    align = "l"
  )

# Number of locations in 2010
loc_2010 <- 
  brfss_df %>% 
  filter(year == 2010) %>% 
  group_by(locationabbr) %>% 
  summarize(n_locations = n()/5) %>% 
  filter(n_locations >= 7) %>% 
  arrange(n_locations)

loc_2010 %>% 
  knitr::kable(
    caption = "Number of locations in 2010",
    align = "l"
  )
```
In 2002, there are `6` states in which 7 or more locations were observed, including ``r pull(loc_2002, locationabbr)``, while in 2010, ``r nrow(loc_2010)`` states met the above conditions and they were ``r pull(loc_2010, locationabbr)``, respectively.

+ Construct a dataset that is limited to `Excellent` responses, and contains, year, state, and a variable that averages the `data_value` across locations within a state. Make a "spaghetti" plot of this average value over time within a state.
```{r, fig.width = 9.5, warning = FALSE}
# Construct a dataset
response_in_state <-   
  brfss_df %>% 
  filter(response == "Excellent") %>% 
  group_by(year, locationabbr) %>% 
  summarize(
    mean_value = mean(data_value, na.rm = TRUE)
  )

# A "spaghetti" plot
response_in_state %>% 
  ggplot(aes(x = year, y = mean_value, color = locationabbr)) + 
  geom_line(size = .3) + 
  theme(
    legend.position = "right"
  ) + 
  labs(
    title = "The average value of Excellent responses within a state",
    caption = "Data from the p8105 package"
  )
```

+ Make a two-panel plot showing, for the years 2006, and 2010, distribution of `data_value` for responses("Poor" to "Excellent") among locations in NY state.
```{r, fig.width =9}
brfss_df %>% 
  filter(
    year %in% c(2006, 2010) & locationabbr == "NY") %>% 
  ggplot(aes(x = data_value, fill = response)) + 
  geom_density(alpha = .5) +  
  facet_grid(. ~ year) + 
  labs(
    y = "Mean data value in NY State",
    title = "Data value distribution in 2006 vs. 2010",
    caption = "Data from 08105 package"
  )
```


## Problem 3

**Load the data `accel_data`**
```{r}
# Load the data
accel_raw <- 
  read_csv("./data/accel_data.csv")
```

**Answer the following question**  
+ Tidy and wrangle the data
```{r}
accel_df <- 
  accel_raw %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_prefix = "activity_",
    names_to = "minute",
    values_to = "activity"
  ) %>% 
  mutate(
    minute = as.numeric(minute),
    dow = ifelse(day %in% weekdays(as.Date("2021-10-16") + 0:1), "weekend", "weekday")
  ) %>% 
  relocate(week, day_id, day, dow)
```
+ A short description:
  + The existing variables are ``r names(accel_df)`` and there are ``r nrow(accel_df)`` observations;
  + Variable `week` represents the week number ranging from `1` to `7`;
  + Variable `day_id` represents a day identifier, ranging from `1` to `35`;
  + Variable `day` and `dow` represents the day of a week and whether it is a weekday or weekend;
  + Variable `minute` represents each minute within a 24-hour day, which ranges from `1` to `1440`;
  + Variable `activity` represents the activity value collected with min value ``r min(pull(accel_df, activity))`` and max value ``r max(pull(accel_df, activity))``.

+ Focus on the total activity
```{r, fig.width = 9}
# Aggregate minutes data
ttl_act <- 
  accel_df %>% 
  group_by(week, day) %>% 
  summarize(
    sum_activity = sum(activity)
  )

# Create a table
ttl_act %>% 
  pivot_wider(
    names_from = "day",
    values_from = "sum_activity"
  ) %>% 
  relocate(1, 5, 3, 7, 8, 6, 2, 4) %>% 
  knitr::kable(
    caption = "Total activity thru a day",
    align = "l"
  )

# Draw a plot
ttl_act %>% 
  mutate(
    day = factor(day, levels = weekdays(as.Date("2021-10-18") + 0:6))
  ) %>% 
  ggplot(aes(x = day, y = sum_activity, group = week, color = week)) + 
  geom_point(alpha = .8) + 
  geom_line()
```

From the above plot, in general, the total activity on weekends is less than weekdays.

+ Show the 24-hour activity time courses for each day
```{r, fig.width = 9}
accel_df %>% 
  ggplot(aes(x = minute / 60, y = activity, color = day)) + 
  geom_line() + 
  labs(
    x = "Hours",
    y = "Activity",
    title = "24-hour activity time courses"
  )
```

+ From the above plot, 
  + The activity counts are obviously lower from midnight to early morning;
  + This participant is more active near noon and the late night around 8 pm to 10 pm.
